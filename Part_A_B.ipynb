{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-KkJpr7eTPl"
      },
      "source": [
        "# Visual Recognition Mini Project-1\n",
        "# Part-A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLLHUy6Egw6L"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnNLnvhghJA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS4EmtKYSZmw"
      },
      "source": [
        "## Dataset Preprocessing\n",
        "Preprocess the image and extract the handcrafted feature(here, HOG) from the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QHF14owV7Hz"
      },
      "source": [
        "## Histogram of Oriented Gradients(HOG)\n",
        "HOG features are extracted by dividing an image into small cells, computing gradient orientations for each cell, and merging these orientations into a histogram. This histogram captures the distribution of gradient directions, forming a feature vector that is useful for object detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMOPfhQzXSJf"
      },
      "source": [
        "The function used to do HOG is hog() in skimage. The parameters passed:\n",
        "- image_gray - Grayscaled image\n",
        "- Orientations - Number of orientations considered in histogram - 9\n",
        "- pixels_per_cell - Size of 1 cell - (8,8)\n",
        "- cells_per_block - Number of cells in 1 block - (2,2)\n",
        "- feature_vector - Used to return data as a feature vector - True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18JGqrUtXdfG"
      },
      "source": [
        "## Local Binary Pattern(LBP)\n",
        "LBP features are extracted by comparing each pixel to its neighborings. For each pixel, a binary code is generated by thresholding neighbors based on center pixelâ€™s value. This captures local texture patterns. These binary codes are converted to decimal and then summarized into a histogram, which represents the image's texture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svTGTIHFoSLR"
      },
      "source": [
        "\n",
        "The function used to do LBP is local_binary_pattern() in skimage.feature . The parameters passed:\n",
        "- image_gray - Grayscaled image\n",
        "- lbp_n_points - Number of circular symmetric points around the main pixel - 8\n",
        "- lbp_radius - Radius of circle that is considered for texture analysis - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTBlYqt8LJ-B",
        "outputId": "95329ebf-f8d6-4a19-ee84-36eb55967f45"
      },
      "outputs": [],
      "source": [
        "def extract_hog_features(image):\n",
        "    # Compute HOG features\n",
        "    features = hog(image, orientations=9,pixels_per_cell=(8,8),cells_per_block=(2,2),feature_vector=True)\n",
        "    return features\n",
        "\n",
        "def extract_lbp_features(image):\n",
        "    lbp = local_binary_pattern(image, 8, 1)\n",
        "    lbp_flat = lbp.ravel()\n",
        "    no_ofbins = np.arange(0, 8)\n",
        "    (hist, _) = np.histogram(lbp_flat,bins=no_ofbins)\n",
        "    return hist\n",
        "\n",
        "def extract_features(image): #Extracts and combines HOG and LBP features from the image.\n",
        "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #Convert to grayscale since color doesn't matter for classifying if image has mask or not.\n",
        "    hog_features = extract_hog_features(image_gray)\n",
        "    lbp_features = extract_lbp_features(image_gray)\n",
        "    combined_features = np.concatenate([hog_features, lbp_features])\n",
        "    return combined_features\n",
        "\n",
        "def features_labels(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for label in ['with_mask', 'without_mask']:\n",
        "        folder = os.path.join(dataset_path, label)\n",
        "        for file_name in os.listdir(folder):\n",
        "            file_path = os.path.join(folder, file_name)\n",
        "            image = cv2.imread(file_path)\n",
        "            image = cv2.resize(image, (128, 128)) #Gives error that the array has inhomogeneous shape if all images are not resized to same dimensions\n",
        "            features = extract_features(image) #Extract HOG features from image\n",
        "            data.append(features) #Features\n",
        "            labels.append(label) #Labels\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/dataset/\"\n",
        "X, y = features_labels(dataset_path) #Extract the features and labels from the dataset\n",
        "print(\"Extracted features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wa-cQflhbv_"
      },
      "source": [
        "## Label encoding the labels and test-train split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itnvvpG2hjH_"
      },
      "source": [
        "The test-train split is done such that 80% is train and 20% is test, with random state of 42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N6ZoqERhv8b"
      },
      "outputs": [],
      "source": [
        "# Encode string labels into numerical values for model training\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # e.g., \"with_mask\" becomes 1 and \"without_mask\" becomes 0\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFsalYRPhwuU"
      },
      "source": [
        "## Support Vector Machine(SVM): SVM Classifier Training and Evaluation\n",
        "- SVM classifier with linear kernel and random state of 42.\n",
        "- The SVM classifier is trained on X_train,y_train and the labels are predicted for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqzp7ahyim-a",
        "outputId": "638b9577-bd4f-4b38-fd88-e55d5d87eee4"
      },
      "outputs": [],
      "source": [
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Classifier Accuracy: {:.2f}%\".format(svm_accuracy * 100))\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n",
        "print(\"SVM Confusion Matrix:\") # Confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X48dJ-7irt7"
      },
      "source": [
        "## Multilayer perceptron(MLP): MLP (Neural Network) Classifier Training and Evaluation\n",
        "Parameters:\n",
        "- hidden_layer_sizes - number of neurons in the hidden layer(single hidden layer in MLP)- (100,)(default)\n",
        "- max_iter - maximum number of iterations - 500\n",
        "- random state - Random weights and bias initialization - 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti7LYovKLS2p",
        "outputId": "8f15bf44-7868-4fba-808f-ea58b059e1cd"
      },
      "outputs": [],
      "source": [
        "mlp_classifier = MLPClassifier(max_iter=500, random_state=42)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp_classifier.predict(X_test)\n",
        "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
        "print(\"MLP Classifier Accuracy: {:.2f}%\".format(mlp_accuracy * 100))\n",
        "print(\"MLP Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_mlp, target_names=label_encoder.classes_))\n",
        "print(\"MLP Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_mlp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPzCT02VlEWT"
      },
      "source": [
        "## Comparison of both classifiers\n",
        "- Compare the precision score, recall score, F1 score and accuracy of SVM and MLP Classifiers.\n",
        "- Performance metrics are calculated using macro-average(metrics of both labels are calculated and mean is taken)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnzkCm4-La6s",
        "outputId": "cb2f9eb9-fdb1-40a4-ae86-341a71944b7c"
      },
      "outputs": [],
      "source": [
        "svm_precision = precision_score(y_test, y_pred_svm, average='macro')\n",
        "svm_recall = recall_score(y_test, y_pred_svm, average='macro')\n",
        "svm_f1 = f1_score(y_test, y_pred_svm, average='macro')\n",
        "\n",
        "mlp_precision = precision_score(y_test, y_pred_mlp, average='macro')\n",
        "mlp_recall = recall_score(y_test, y_pred_mlp, average='macro')\n",
        "mlp_f1 = f1_score(y_test, y_pred_mlp, average='macro')\n",
        "\n",
        "results = {\n",
        "    \"Classifier\": [\"SVM\", \"MLP\"],\n",
        "    \"Accuracy\": [svm_accuracy, mlp_accuracy],\n",
        "    \"Precision\": [svm_precision, mlp_precision],\n",
        "    \"Recall\": [svm_recall, mlp_recall],\n",
        "    \"F1 Score\": [svm_f1, mlp_f1]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Performance Comparison of the Classifiers:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fix randomness for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "IMG_SIZE = 224  \n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "LEARNING_RATE = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(data_dir):\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory( \n",
        "        data_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        subset='validation',\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimized CNN Model\n",
        "\n",
        "This function builds a **CNN for binary classification** with:\n",
        "- **4 convolutional blocks** (Conv2D + MaxPooling) for feature extraction.\n",
        "- **GlobalAveragePooling2D** instead of Flatten to reduce overfitting.\n",
        "- **256-unit Dense layer + Dropout (0.5)** for better generalization.\n",
        "- **Sigmoid activation** for binary output.\n",
        "- Compiled with **Adam optimizer** & `binary_crossentropy` loss.\n",
        "- Ensures **reproducibility** with `set_random_seed(42)`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_optimized_model():\n",
        "    tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        # Block 1\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Block 2\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Block 3\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Block 4\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # GlobalAveragePooling instead of Flatten\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "        # Output Layer\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training History Plot\n",
        "\n",
        "Plots accuracy and loss curves to monitor training progress and detect overfitting or underfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history.history['accuracy'], 'bo-', label='Training Accuracy')\n",
        "    plt.plot(epochs, history.history['val_accuracy'], 'ro-', label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history.history['loss'], 'bo-', label='Training Loss')\n",
        "    plt.plot(epochs, history.history['val_loss'], 'ro-', label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training Pipeline\n",
        "\n",
        "- **train_model**: Trains the model, tracks validation performance, and identifies the best epoch based on validation loss.\n",
        "- **main**: Loads data, initializes the model, and starts training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_generator, validation_generator):\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=len(validation_generator)\n",
        "    )\n",
        "\n",
        "    min_val_loss_epoch = history.history[\"val_loss\"].index(min(history.history[\"val_loss\"]))\n",
        "    best_val_loss = history.history[\"val_loss\"][min_val_loss_epoch]\n",
        "    best_val_acc = history.history[\"val_accuracy\"][min_val_loss_epoch]\n",
        "\n",
        "    print(f\"\\nBest Validation Loss: {best_val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy at Best Loss: {best_val_acc * 100:.2f}%\")\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "def main():\n",
        "    data_dir = 'dataset'\n",
        "    train_generator, validation_generator = load_data(data_dir)\n",
        "    model = create_optimized_model()\n",
        "    train_model(model, train_generator, validation_generator)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note\n",
        "- The below code is using the VGG16 model which is pretrained but showed promising results in the training and validation accuracy.\n",
        "- It has given a validation accuracy of 99.76% while the above custom optimized CNN model gave validation accuracy of 98.41%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 150 \n",
        "\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale = 1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "    \n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory( \n",
        "        data_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "        seed = 42\n",
        "    )\n",
        "    \n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        subset='validation',\n",
        "        seed = 42\n",
        "    )\n",
        "    \n",
        "    return train_generator, validation_generator\n",
        "    \n",
        "def create_model():    \n",
        "    base_model = tf.keras.applications.VGG16(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    tf.keras.utils.set_random_seed(42)\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    \n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    output =tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy']) #adam ->1e-4, 1e-3\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "def plot_history(history):\n",
        "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "    \n",
        "    # Plot accuracy\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history.history['accuracy'], 'bo-', label='Training Accuracy')\n",
        "    plt.plot(epochs, history.history['val_accuracy'], 'ro-', label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history.history['loss'], 'bo-', label='Training Loss')\n",
        "    plt.plot(epochs, history.history['val_loss'], 'ro-', label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def train_model(model, train_generator, validation_generator):\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=len(validation_generator),\n",
        "    )\n",
        "\n",
        "    # Find the epoch with the minimum validation loss\n",
        "    min_val_loss_epoch = history.history[\"val_loss\"].index(min(history.history[\"val_loss\"]))\n",
        "    best_val_loss = history.history[\"val_loss\"][min_val_loss_epoch]\n",
        "    best_val_acc = history.history[\"val_accuracy\"][min_val_loss_epoch]\n",
        "\n",
        "    print(f\"\\nBest Validation Loss: {best_val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy at Best Loss: {best_val_acc * 100:.2f}%\")\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "    \n",
        "def main():\n",
        "    data_dir = 'dataset'\n",
        "    train_generator, validation_generator = load_data(data_dir)\n",
        "    model = create_model()\n",
        "    train_model(model, train_generator, validation_generator)\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
